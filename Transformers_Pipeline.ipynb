{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaswanthd333/Huggingface_LLM/blob/main/Transformers_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blrz3BBl2OaC"
      },
      "source": [
        "# Transformers pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CebX1dCg2OaF"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79ziL3QQ2OaG",
        "outputId": "bdf72a74-8d71-4032-dffa-09118440ef7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 75ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzayprdk2OaG",
        "outputId": "a96540b5-a1fe-4744-b591-e1a65cb25a26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9986820816993713}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Sentiment analysis of given text\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"Langchain looks like an interesting subject\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO2AsB952OaI",
        "outputId": "628c780e-3342-45e9-c261-924ec0cdeeb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598050713539124},\n",
              " {'label': 'NEGATIVE', 'score': 0.9996367692947388}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this OpenAI API pricing!\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOAmU0Is2OaJ",
        "outputId": "9336a3bc-a3de-4696-9697-3dcad733231a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'Formula 1 Technical Regulations changed drastically from 2026 season.',\n",
              " 'labels': ['Technology', 'Sports', 'Entertainment'],\n",
              " 'scores': [0.9453946352005005, 0.0380333736538887, 0.01657198742032051]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Classification of sentences according to categories\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"Formula 1 Technical Regulations changed drastically from 2026 season.\",\n",
        "    candidate_labels=[\"Technology\",\"Entertainment\",\"Sports\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj-IkVq52OaJ",
        "outputId": "173ae3a4-3dd5-45af-a9d2-154cf1031508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this Langchain course, we will teach you how to do Langchain concepts.\\n\\nLangchain-1 is a free online course. The course is split into two parts: the first section is for beginners, and the second section is for experienced students. The course is written in English.\\n\\nLangchain 3 is a free online course. The course is split into two parts: the first section is for beginners, and the second section is for experienced students. The course is written in English.\\n\\nLangchain 4 is a free online course. The course is split into two parts: the first section is for beginners, and the second section is for experienced students. The course is written in English.\\n\\nLangchain 5 is a free online course. The course is split into two parts: the first section is for beginner, and the second section is for experienced students. The course is written in English.\\n\\nLangchain 6 is a free online course. The course is split into two parts: the first section is for beginner, and the second section is for experienced students. The course is written in English.\\n\\nLangchain 7 is a free online course. The course is split into two parts: the first section is for beginner, and the second section is for experienced students. The course is'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Text generation from the given text\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this Langchain course, we will teach you how to do Langchain concepts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aysDl1r42OaK",
        "outputId": "273622db-4abb-4001-ce08-723c1aa04dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to do Langchain concepts in a manner that is not difficult to understand.\\n\\n\\nTo learn how to do this, you need to find a good technique. For example, you can use Langchain concepts in a way that is easy to grasp.\\nThis course will show you how to use Langchain concepts in a way that is not difficult to understand.\\nThe easiest way to do this is to use a simple Langchain concept.\\nThis course will show you how to use Langchain concepts in a way that is not difficult to understand.\\nThe simplest way to do this is to use a simple Langchain concept.\\nThis course will show you how to use Langchain concepts in a way that is not difficult to understand.\\nThe simplest way to do this is to use a simple Langchain concept.\\nThis course will show you how to use Langchain concepts in a way that is not difficult to understand.\\nThis course will show you how to use Langchain concepts in a way that is not difficult to understand.\\nThis course will show you how to use Langchain concepts in a way that is not difficult to understand.\\nThis course will show you how to use Langchain concepts in a way that is not difficult to understand.\\nThis course will show you how to'},\n",
              " {'generated_text': 'In this course, we will teach you how to do Langchain concepts with a wide range of experience, understanding the basics of the Langchain concepts, and applying them to all platforms.\\n\\n\\n\\nLangchain\\nLearning Langchain\\nLangchain\\nLangchain\\nThe Langchain is a course taught in a course by a non-Langchain.\\nFor more information on Langchain, click here.\\nLangchain\\nLangchain\\nLearning Langchain\\nLearning Langchain\\nLangchain\\nLearning Langchain\\nLangchain\\nLearning Langchain\\nLearning Langchain\\nLangchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain\\nLearning Langchain'},\n",
              " {'generated_text': \"In this course, we will teach you how to do Langchain concepts and implement them in a way that can be applied to your own projects and applications.\\n\\n\\n\\nFirst step is to get started. Let’s start with Langchain concepts. First, a simple example is what I did in the previous tutorial. In my case, the last step is to use the first step to make your project stand out of a few different constraints.\\nFirst, some rules of thumb will be simple for the first step. First, you want to make your project stand out from the rest of the problem. Then you want to make sure that you are using the right tool. Then, your project is a simple way to use the right tool.\\nSecondly, you want to make sure that you have the right tools to create your project. Second, you want to add some useful tools to your project. All of the tools in this article will depend on how you use them. Here's a simple example of all of the tools in this tutorial.\\nNext, you want to add some useful tools to your project. First, you want to add some useful tools to your project. Second, you want to add some useful tools to your project.\\nNow, you want to add some useful tools to your project. Let’s\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Text generation using distilgpt2 model\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to do Langchain concepts\",\n",
        "    max_length=50,\n",
        "    num_return_sequences=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Wccl1z2OaL",
        "outputId": "dd11ce2e-9244-421e-b927-a46d04f4aadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.19619743525981903,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical',\n",
              "  'sequence': 'This course will teach you all about mathematical models.'},\n",
              " {'score': 0.04052726551890373,\n",
              "  'token': 38163,\n",
              "  'token_str': ' computational',\n",
              "  'sequence': 'This course will teach you all about computational models.'},\n",
              " {'score': 0.033017825335264206,\n",
              "  'token': 27930,\n",
              "  'token_str': ' predictive',\n",
              "  'sequence': 'This course will teach you all about predictive models.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Mask fill\n",
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klGlAkBz2OaL",
        "outputId": "a003cec0-be6a-45c1-a429-08717f359fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': np.float32(0.9903352),\n",
              "  'word': 'Yaswanth',\n",
              "  'start': 11,\n",
              "  'end': 19},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': np.float32(0.99776757),\n",
              "  'word': 'TCS',\n",
              "  'start': 34,\n",
              "  'end': 37},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': np.float32(0.9962852),\n",
              "  'word': 'Kolkata',\n",
              "  'start': 41,\n",
              "  'end': 48}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Named Entity Recognition\n",
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Yaswanth and I work at TCS in Kolkata.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKKtc4QN2OaM",
        "outputId": "bac253b4-04c8-41f4-877d-41fb61495a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.5612614750862122,\n",
              " 'start': 34,\n",
              " 'end': 48,\n",
              " 'answer': 'TCS in Kolkata'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Question answering using context\n",
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Yaswanth and I work at TCS in Kolkata.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2E3HpqP2OaM",
        "outputId": "2a7315fe-ca9c-4b87-86b2-81f09522220b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' The number of engineering graduates in the United States has declined in recent years . China and India graduate six and eight times as many traditional engineers as the U.S. does . Rapidly developing economies such as China continue to encourage and advance the teaching of engineering . There are declining offerings in engineering subjects dealing with infrastructure, infrastructure, the environment, and related issues .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Summarization\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0w-DYkB2OaN",
        "outputId": "eef9336b-0ed2-44ea-bbc7-aa16c85b2c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'This course is produced by TCS.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# translation\n",
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Ce cours est produit par TCS.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image classifier\n",
        "from transformers import pipeline\n",
        "\n",
        "image_classifier = pipeline(\n",
        "    task=\"image-classification\", model=\"google/vit-base-patch16-224\"\n",
        ")\n",
        "result = image_classifier(\n",
        "    \"https://cdn-uploads.huggingface.co/production/uploads/6402366d06c715b9340068ae/4kzu2tiVTJwuy0q_ZjuRN.png\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ybXMKSLy3XP",
        "outputId": "d2e21683-410b-4c1e-ad53-681e2b471fbb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'CD player', 'score': 0.4938413202762604}, {'label': 'tape player', 'score': 0.11106492578983307}, {'label': 'radio, wireless', 'score': 0.10971023142337799}, {'label': 'oscilloscope, scope, cathode-ray oscilloscope, CRO', 'score': 0.03644983097910881}, {'label': 'cassette player', 'score': 0.03403060883283615}]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}